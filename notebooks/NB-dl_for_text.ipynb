{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5ZZS6o0Z8Oj"
      },
      "source": [
        "# 11장 자연어 처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGXhJe5XZ8Ou"
      },
      "source": [
        "##  IMDB 영화 후기 데이터셋 벡터화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfwyzgmXZ8Ou"
      },
      "source": [
        "IMDB 데이터셋을 직접 다운로드하여 벡터화하는 과정을 살펴본다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaO7ilwSZ8Ou"
      },
      "source": [
        "준비 과정 1: 데이터셋 다운로드 압축 풀기\n",
        "\n",
        "압축을 풀면 아래 구조의 디렉토리가 생성된다.\n",
        "\n",
        "```\n",
        "aclImdb/\n",
        "...train/\n",
        "......pos/\n",
        "......neg/\n",
        "...test/\n",
        "......pos/\n",
        "......neg/\n",
        "```\n",
        "\n",
        "`train`의 `pos`와 `neg` 서브디렉토리에 각각 12,500개의 긍정과 부정 후기가\n",
        "포함되어 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eScCXFlWZ8Ou",
        "outputId": "1bc69ce0-3c4a-4729-88e6-9618a8c6bcb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  5724k      0  0:00:14  0:00:14 --:--:-- 13.2M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMRKwRM9Z8Ou"
      },
      "source": [
        "`aclImdb/train/unsup` 서브디렉토리는 필요 없기에 삭제한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2xsKw4vPZ8Ou"
      },
      "outputs": [],
      "source": [
        "import platform\n",
        "\n",
        "if platform.system() == 'Linux':\n",
        "    !rm -r aclImdb/train/unsup\n",
        "else:\n",
        "    import shutil\n",
        "    unsup_path = './aclImdb/train/unsup'\n",
        "    shutil.rmtree(unsup_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rZ3a9ETZ8Ou"
      },
      "source": [
        "긍정 후기 하나의 내용을 살펴보자.\n",
        "모델 구성 이전에 훈련 데이터셋을 살펴 보고\n",
        "모델에 대한 직관을 갖는 과정이 항상 필요하다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK5FRFX0Z8Ou",
        "outputId": "279472b0-bf4d-48d2-d172-ac1c80f64ddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    !cat aclImdb/train/pos/4077_10.txt\n",
        "else:\n",
        "    with open('aclImdb/train/pos/4077_10.txt', 'r') as f:\n",
        "        text = f.read()\n",
        "        print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfeoV0YCZ8Ov"
      },
      "source": [
        "준비 과정 2: 검증셋 준비\n",
        "\n",
        "훈련셋의 20%를 검증셋으로 떼어낸다.\n",
        "이를 위해 `aclImdb/val` 디렉토리를 생성한 후에\n",
        "긍정과 부정 훈련셋 모두 무작위로 섞은 후 그중 20%를 검증셋 디렉토리로 옮긴다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xX30tWVBZ8Ov"
      },
      "outputs": [],
      "source": [
        "import os, pathlib, shutil, random\n",
        "\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(val_dir / category)            # val 디렉토리 생성\n",
        "    files = os.listdir(train_dir / category)\n",
        "\n",
        "    random.Random(1337).shuffle(files)         # 훈련셋 무작위 섞기\n",
        "\n",
        "    num_val_samples = int(0.2 * len(files))    # 20% 지정 후 검증셋으로 옮기기\n",
        "    val_files = files[-num_val_samples:]\n",
        "\n",
        "    for fname in val_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fljBC3puZ8Ov"
      },
      "source": [
        "준비 과정 3: 텐서 데이터셋 준비\n",
        "\n",
        "`text_dataset_from_directory()` 함수를 이용하여\n",
        "훈련셋, 검증셋, 테스트셋을 준비한다.\n",
        "자료형은 모두 `Dataset`이며, 배치 크기는 32를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e41g6BtPZ8Ov",
        "outputId": "39e961d7-695c-42ca-d6df-f3dd2a4e24b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size=batch_size\n",
        "    )\n",
        "\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        "    )\n",
        "\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLi_rBmlZ8Ov"
      },
      "source": [
        "각 데이터셋은 배치로 구분되며\n",
        "입력은 `tf.string` 텐서이고, 타깃은 `int32` 텐서이다.\n",
        "크기는 모두 32이며 지정된 배치 크기이다.\n",
        "예를 들어, 첫째 배치의 입력과 타깃 데이터의 정보는 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G05FSfO1Z8Ov",
        "outputId": "5ac5512f-5679-4219-9150-031f3b0e93fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b'In the days before gore and sex took over, real horror films were made. Castle of Blood is, in my estimation, one of the finest, although other reviewers have given it mixed ratings. In an odd sort of way it reminds of the more recent The Others, which was in the theaters a couple of years ago.<br /><br />Director Antonio Margheriti remade his own picture in 1970 titling it this time Web of the Spider (AKA Nella Stretta Morsa del Ragno). Why he did this I do not understand, although the remake starred Anthony Franciosa and Klaus Kinski and was very good in its own right. Perhaps he saw a good story and wished to tailor it more to American audiences. I do not really know. It is interesting that he did the original in black and white and the remake in color.<br /><br />Castle of Blood is excellent Italian Gothic. La Danza Macabra is said to be an unpublished work of Edgar Allen Poe, who \"appears\" in this film. Poe and Lord Blackwood, owner of a haunted castle, bet American writer Alan Foster (George Riviere) that he cannot spend All Souls Night in said castle and survive. Foster eagerly accepts the bet but soon regrets it, for he is witness to a series of murders committed by ghosts. It seems that the ghosts come back to life once every few years but are doomed to re-enact the crimes they committed in life. Lord Blackwood conveniently forgot to tell Foster that his blood is needed for them to resurrect themselves on the next All Souls Night! <br /><br />It does not take Foster and the beautiful Elisabeth Blackwood (portrayed by the incomparable Barbara Steele) long to fall in love, even though their romance is doomed, because Elisabeth is one of the ghosts. I will not give the ending away, but will just say that Castle of Blood is every bit a romantic tragedy as it is a horror story. <br /><br />Comments. This film is greatly atmospheric, even by the excellent standards of the Italians. My personal opinion is they do true horror better than anybody, and the somewhat dim black and white filming only enhances this. In fairness, Web of the Spider was fine in its own right, even with color and greater brightness. I loved the lingering shots, something most modern day directors do not have the patience for. Indeed, when Alan first enters the doomed castle, we are treated to several minutes of him doing nothing but roaming around from room to room, the dread ands unease building in his face and mannerisms. By the time the first ghost appears, the audience is thoroughly primed and ready. There is wonderful dialogue between Alan and the ghosts, something else not often done in standard ghost stories. There are also memorable scenes, very visual for this type of film. Elisabeth\\'s \"murder\" and the dance scene (reminds somewhat of the similar dance of the ghouls in 1962\\'s Carnival of Souls) were particularly good.<br /><br />Sadly, few general interest viewers will ever hear of, much less see, this film. That is a shame, for this one is a cut above the rest. I got my copy from Sinister Cinema and am not certain if it can be purchased anywhere else. For persons interested in this genre, it is a must see.', shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "\n",
        "    # 예제: 첫째 배치의 첫째 후기\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM3uJTQVlJSy"
      },
      "source": [
        "### 11.3.3 시퀀스 활용법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXZ34Qg7lJSy"
      },
      "source": [
        "**정수 벡터 데이터셋 준비**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoVifu3DlJSy"
      },
      "source": [
        "훈련셋의 모든 후기 문장을 정수들의 벡터로 변환한다.\n",
        "단, 후기 문장이 최대 600개의 단어만 포함하도록 한다.\n",
        "또한 사용되는 어휘는 빈도 기준 최대 2만 개로 제한한다.\n",
        "\n",
        "- `max_length = 600`\n",
        "- `max_tokens = 20000`\n",
        "- `output_sequence_length=max_length`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "orh58qTYlJSy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "max_length = 600\n",
        "max_tokens = 20000\n",
        "\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "# 어휘 색인 생성 대상 훈련셋 후기 텍스트 데이터셋\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y))\n",
        "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T94MVnSHlJSy"
      },
      "source": [
        "변환된 첫째 배치의 입력과 타깃 데이터의 정보는 다음과 같다.\n",
        "`output_sequence_length=600`으로 지정하였기에 모든 문장은 단어를 최대 600개에서\n",
        "잘린다. 따라서 생성되는 정수들의 벡터는 길이가 모두 600으로 지정된다.\n",
        "물론 문장이 600개보다 적은 수의 단어를 사용한다면 나머지는 0으로 채워진다.\n",
        "또한 벡터에 사용된 정수는 2만보다 작은 값이며,\n",
        "이는 빈도가 가장 높은 2만개의 단어만을 대상(`max_tokens=20000`)으로 했기 때문이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B-SbA7rlJSy",
        "outputId": "5f28fe6a-fc80-4917-c55b-19651d336f2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32, 600)\n",
            "inputs.dtype: <dtype: 'int64'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(\n",
            "[  109  2304    11    20   348  1008    21  6988     3   248    11    64\n",
            "  3618 15266     3     4   384   511    60    66     6  2647    17     2\n",
            "  3224 10521     5     2   700  5367    41    39   105    83  1783  4574\n",
            "    16   459 15320     2    85   189   332    14   127     3    81     8\n",
            "    11   511    67   124  2142    37    65   408  1285     3     2  5362\n",
            "    60   332   205  1986  3766 11558     1     1  1472  1664    37     2\n",
            "   332    17     4   408  3676     3    14     2  1096   417  1763     8\n",
            "   511    28    14   777    58     4  1101     3    14    22    53   656\n",
            "    17     2  7258    81     3    35     8   456   115    22  1271  1742\n",
            "    89   347    15     2  2156  1100  1945     6   685     1 19430  4934\n",
            "     6   399     4  3224     8   644     6   923     3 12280    11   384\n",
            "  7258   511    16    65  2200   896    89    60    14    63    32     8\n",
            "    25   349 12865     1     1 10498   252    34  1296   215    15     4\n",
            "   251    36   408    40   657     3    14 15972   564    17     1     1\n",
            "    48    23   105  2095     3    47    53   146  8302    43    87     2\n",
            "  3224  2676  1886  2133     3    65   420   457     2  5490  1799    23\n",
            "   600     8    11   435    17  2985    81  5563     6     2  3224  2523\n",
            "     1    45    24    26    22   108    11    20     3    39    11   878\n",
            "   541   190     9    47     5   123    62    11    20     7    53   185\n",
            "     6   746    16     4  7090    20     3     4    64    24    77    22\n",
            "   808   101   931     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0], shape=(600,), dtype=int64)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in int_train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCrjK1-zUwFj"
      },
      "source": [
        "**트랜스포머 구현**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH2T-AQOUwFj"
      },
      "source": [
        "위 그림에서 설명된 트랜스포머 인코더를 층(layer)으로 구현하면 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "X6g33CzrUwFk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtXomfGDUwFk"
      },
      "source": [
        "**트랜스포머 인코더 활용 모델**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPSowlcGUwFk"
      },
      "source": [
        "훈련 데이터셋이 입력되면 먼저 단어 임베딩을 이용하여\n",
        "단어들 사이의 연관성을 찾는다.\n",
        "이후 트랜스포머 인코더로 셀프 어텐션을 적용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "hxbIVhi3UwFk",
        "outputId": "9f43fde9-b84b-4d0e-d690-ce5959bebb73"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m5,120,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_encoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m543,776\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_encoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">543,776</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,664,033\u001b[0m (21.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,664,033</span> (21.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,664,033\u001b[0m (21.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,664,033</span> (21.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "vocab_size = 20000\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "\n",
        "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "# 길이가 256인 1차원 어레이로 변환\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rJ82rMIUwFl"
      },
      "source": [
        "훈련 과정은 특별한 게 없다.\n",
        "테스트셋에 대한 정확도가 87.5% 정도로 바이그램 모델보다 좀 더 낮다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2BDEYHaUwFl",
        "outputId": "a81a5913-fdf8-44f9-f2ce-d4f983479c51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3385 - accuracy: 0.8547INFO:tensorflow:Assets written to: transformer_encoder/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: transformer_encoder/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 146s 233ms/step - loss: 0.3385 - accuracy: 0.8547 - val_loss: 0.3318 - val_accuracy: 0.8594\n",
            "Epoch 2/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2989 - accuracy: 0.8723INFO:tensorflow:Assets written to: transformer_encoder/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: transformer_encoder/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 141s 225ms/step - loss: 0.2989 - accuracy: 0.8723 - val_loss: 0.3204 - val_accuracy: 0.8634\n",
            "Epoch 3/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2680 - accuracy: 0.8893INFO:tensorflow:Assets written to: transformer_encoder/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: transformer_encoder/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 142s 227ms/step - loss: 0.2680 - accuracy: 0.8893 - val_loss: 0.3118 - val_accuracy: 0.8706\n",
            "Epoch 4/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.9039INFO:tensorflow:Assets written to: transformer_encoder/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: transformer_encoder/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 142s 226ms/step - loss: 0.2386 - accuracy: 0.9039 - val_loss: 0.3090 - val_accuracy: 0.8688\n",
            "Epoch 5/20\n",
            "625/625 [==============================] - 141s 225ms/step - loss: 0.2071 - accuracy: 0.9178 - val_loss: 0.3177 - val_accuracy: 0.8736\n",
            "Epoch 6/20\n",
            "625/625 [==============================] - 138s 220ms/step - loss: 0.1833 - accuracy: 0.9293 - val_loss: 0.3281 - val_accuracy: 0.8756\n",
            "Epoch 7/20\n",
            "625/625 [==============================] - 138s 220ms/step - loss: 0.1550 - accuracy: 0.9396 - val_loss: 0.3379 - val_accuracy: 0.8718\n",
            "Epoch 8/20\n",
            "625/625 [==============================] - 138s 220ms/step - loss: 0.1288 - accuracy: 0.9514 - val_loss: 0.3661 - val_accuracy: 0.8638\n",
            "Epoch 9/20\n",
            "625/625 [==============================] - 136s 217ms/step - loss: 0.1069 - accuracy: 0.9627 - val_loss: 0.4106 - val_accuracy: 0.8592\n",
            "Epoch 10/20\n",
            "625/625 [==============================] - 138s 221ms/step - loss: 0.0873 - accuracy: 0.9678 - val_loss: 0.4019 - val_accuracy: 0.8664\n",
            "Epoch 11/20\n",
            "625/625 [==============================] - 141s 225ms/step - loss: 0.0717 - accuracy: 0.9740 - val_loss: 0.3873 - val_accuracy: 0.8676\n",
            "Epoch 12/20\n",
            "625/625 [==============================] - 138s 221ms/step - loss: 0.0545 - accuracy: 0.9805 - val_loss: 0.4250 - val_accuracy: 0.8578\n",
            "Epoch 13/20\n",
            "625/625 [==============================] - 138s 221ms/step - loss: 0.0484 - accuracy: 0.9823 - val_loss: 0.4858 - val_accuracy: 0.8568\n",
            "Epoch 14/20\n",
            "625/625 [==============================] - 136s 218ms/step - loss: 0.0403 - accuracy: 0.9862 - val_loss: 0.5500 - val_accuracy: 0.8518\n",
            "Epoch 15/20\n",
            "625/625 [==============================] - 138s 221ms/step - loss: 0.0343 - accuracy: 0.9876 - val_loss: 0.5723 - val_accuracy: 0.8562\n",
            "Epoch 16/20\n",
            "625/625 [==============================] - 136s 218ms/step - loss: 0.0315 - accuracy: 0.9892 - val_loss: 0.6242 - val_accuracy: 0.8476\n",
            "Epoch 17/20\n",
            "625/625 [==============================] - 137s 219ms/step - loss: 0.0292 - accuracy: 0.9906 - val_loss: 0.6157 - val_accuracy: 0.8554\n",
            "Epoch 18/20\n",
            "625/625 [==============================] - 136s 217ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.6662 - val_accuracy: 0.8500\n",
            "Epoch 19/20\n",
            "625/625 [==============================] - 139s 222ms/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.7366 - val_accuracy: 0.8456\n",
            "Epoch 20/20\n",
            "625/625 [==============================] - 139s 222ms/step - loss: 0.0176 - accuracy: 0.9937 - val_loss: 0.7559 - val_accuracy: 0.8476\n",
            "782/782 [==============================] - 53s 67ms/step - loss: 0.3071 - accuracy: 0.8674\n",
            "Test acc: 0.867\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"transformer_encoder\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\n",
        "    \"transformer_encoder\",\n",
        "    custom_objects={\"TransformerEncoder\": TransformerEncoder})\n",
        "\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tEOxNV_UwFl"
      },
      "source": [
        "**단어 위치 인코딩**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHQszXy-UwFl"
      },
      "source": [
        "다음 `PositionalEmbedding` 층 클래스는 두 개의 임베딩 클래스를 사용한다.\n",
        "하나는 보통의 단어 임베딩이며,\n",
        "다른 하나는 단어의 위치 정보를 임베딩한다.\n",
        "각 임베딩의 출력값을 합친 값을 트랜스포머에게 전달하는 역할을 수행한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRiJ-vBXUwFm"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG2Db4SRUwFm"
      },
      "source": [
        "**단어위치인식 트랜스포머 아키텍처**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq24k0wlUwFm"
      },
      "source": [
        "아래 코드는 `PositionalEmbedding` 층을 활용하여 트랜스포머 인코더가\n",
        "단어위치를 활용할 수 있도록 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYcxHlk7UwFm"
      },
      "outputs": [],
      "source": [
        "vocab_size = 20000\n",
        "sequence_length = 600\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba70a092-839a-4307-ec8a-a28610059829",
        "id": "7s2wm615mYpr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " positional_embedding (Posi  (None, None, 256)         5273600   \n",
            " tionalEmbedding)                                                \n",
            "                                                                 \n",
            " transformer_encoder_1 (Tra  (None, None, 256)         543776    \n",
            " nsformerEncoder)                                                \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Gl  (None, 256)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5817633 (22.19 MB)\n",
            "Trainable params: 5817633 (22.19 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba70a092-839a-4307-ec8a-a28610059829",
        "id": "MYhJs3u8mYps"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.5303 - accuracy: 0.7409INFO:tensorflow:Assets written to: full_transformer_encoder/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: full_transformer_encoder/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 212s 334ms/step - loss: 0.5303 - accuracy: 0.7409 - val_loss: 0.3390 - val_accuracy: 0.8530\n",
            "Epoch 2/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2971 - accuracy: 0.8765INFO:tensorflow:Assets written to: full_transformer_encoder/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: full_transformer_encoder/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 202s 322ms/step - loss: 0.2971 - accuracy: 0.8765 - val_loss: 0.3021 - val_accuracy: 0.8730\n",
            "Epoch 3/20\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2351 - accuracy: 0.9072INFO:tensorflow:Assets written to: full_transformer_encoder/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: full_transformer_encoder/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 189s 302ms/step - loss: 0.2351 - accuracy: 0.9072 - val_loss: 0.2917 - val_accuracy: 0.8864\n",
            "Epoch 4/20\n",
            "625/625 [==============================] - 197s 315ms/step - loss: 0.1961 - accuracy: 0.9236 - val_loss: 0.4036 - val_accuracy: 0.8482\n",
            "Epoch 5/20\n",
            "625/625 [==============================] - 202s 323ms/step - loss: 0.1619 - accuracy: 0.9391 - val_loss: 0.4399 - val_accuracy: 0.8160\n",
            "Epoch 6/20\n",
            "625/625 [==============================] - 203s 324ms/step - loss: 0.1373 - accuracy: 0.9484 - val_loss: 0.5411 - val_accuracy: 0.8412\n",
            "Epoch 7/20\n",
            "625/625 [==============================] - 198s 317ms/step - loss: 0.1160 - accuracy: 0.9570 - val_loss: 0.3829 - val_accuracy: 0.8828\n",
            "Epoch 8/20\n",
            "625/625 [==============================] - 204s 327ms/step - loss: 0.0996 - accuracy: 0.9639 - val_loss: 0.3933 - val_accuracy: 0.8860\n",
            "Epoch 9/20\n",
            "625/625 [==============================] - 194s 309ms/step - loss: 0.0800 - accuracy: 0.9712 - val_loss: 0.4089 - val_accuracy: 0.8772\n",
            "Epoch 10/20\n",
            "625/625 [==============================] - 187s 298ms/step - loss: 0.0652 - accuracy: 0.9769 - val_loss: 0.5583 - val_accuracy: 0.8536\n",
            "Epoch 11/20\n",
            "625/625 [==============================] - 187s 299ms/step - loss: 0.0479 - accuracy: 0.9840 - val_loss: 0.7802 - val_accuracy: 0.8756\n",
            "Epoch 12/20\n",
            "625/625 [==============================] - 187s 299ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 0.4672 - val_accuracy: 0.8744\n",
            "Epoch 13/20\n",
            "625/625 [==============================] - 189s 301ms/step - loss: 0.0329 - accuracy: 0.9888 - val_loss: 0.7663 - val_accuracy: 0.8736\n",
            "Epoch 14/20\n",
            "625/625 [==============================] - 188s 301ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.6569 - val_accuracy: 0.8756\n",
            "Epoch 15/20\n",
            "625/625 [==============================] - 189s 302ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.7507 - val_accuracy: 0.8752\n",
            "Epoch 16/20\n",
            "625/625 [==============================] - 190s 303ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.9361 - val_accuracy: 0.8756\n",
            "Epoch 17/20\n",
            "625/625 [==============================] - 188s 300ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 1.1054 - val_accuracy: 0.8420\n",
            "Epoch 18/20\n",
            "625/625 [==============================] - 188s 301ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 1.0927 - val_accuracy: 0.8718\n",
            "Epoch 19/20\n",
            "625/625 [==============================] - 186s 297ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 1.1077 - val_accuracy: 0.8674\n",
            "Epoch 20/20\n",
            "625/625 [==============================] - 185s 296ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 1.2667 - val_accuracy: 0.8626\n",
            "782/782 [==============================] - 63s 80ms/step - loss: 1.3448 - accuracy: 0.5012\n",
            "Test acc: 0.501\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"full_transformer_encoder\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\n",
        "    \"full_transformer_encoder\",\n",
        "    custom_objects={\"TransformerEncoder\": TransformerEncoder,\n",
        "                    \"PositionalEmbedding\": PositionalEmbedding})\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsHTQVECT_5r"
      },
      "source": [
        "## 시퀀스-투-시퀀스 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcAvn1b2mYps"
      },
      "source": [
        "영어-스페인어 기계 번역과 영어-한국어 기계 번역을 작은 데이터셋을 이용하여 훈련시켜본다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kRw8L0jT_5r"
      },
      "source": [
        "### 영어-스페인어 기계 번역"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNmStOHcmYpv"
      },
      "source": [
        "**텍스트 데이터셋 다운로드**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9lT4MPWmYpv"
      },
      "source": [
        "영어와 스페인어 텍스트가 담긴 압축 파일을 다운로드 한 후에 압축을 풀면\n",
        "\"spa.txt\" 파일이 생성된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4zqvFdKT_5r",
        "outputId": "1e97f4d7-d743-45d0-d29f-d94872e59484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-12-16 18:29:23--  https://www.manythings.org/anki/spa-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5413153 (5.2M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "spa-eng.zip         100%[===================>]   5.16M  3.99MB/s    in 1.3s    \n",
            "\n",
            "2023-12-16 18:29:25 (3.99 MB/s) - ‘spa-eng.zip’ saved [5413153/5413153]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.manythings.org/anki/spa-eng.zip\n",
        "!unzip -q spa-eng.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZPJVfURmYpv"
      },
      "source": [
        "\"spa.txt\" 파일은 각각의 줄은 아래와 같이 영어 텍스트, 스페인어 텍스트, 기타 정보가 탭(tab) 키로 구분되어 있다.\n",
        "\n",
        "```\n",
        "Finally, it's Friday.\tAl fin es viernes.\tCC-BY 2.0 (France) Attribution: tatoeba.org #433868 (CK) & #1427385 (marcelostockle)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUOV3wR5mYpv"
      },
      "source": [
        "아래 코드는 \"spa.txt\"에 포함된 각 줄의 내용을 항목으로 갖는 리스트인 `text_pairs`를 생성한다.\n",
        "단 각 항목은 (영어 텍스트, 스페인어 텍스트)로 구성된 튜플이며, 각각의 줄에 포함된 기타 정보는 버린다.\n",
        "또한 스페인어 텍스트의 처음과 끝에 각각 `'[start] '` 와 `' [end]'`를 추가한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adbnHDocT_5r"
      },
      "outputs": [],
      "source": [
        "text_file = \"spa.txt\"\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    english, spanish, _ = line.split(\"\\t\")\n",
        "    spanish = \"[start] \" + spanish + \" [end]\"\n",
        "    text_pairs.append((english, spanish))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmxdSnUimYpv"
      },
      "source": [
        "`text_pairs`에 포함된 임의의 항목을 확인하면 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN_IurD9T_5s",
        "outputId": "9f1afe71-546f-4b11-ec09-f2eb089174ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('You must be more polite.', '[start] Tienes que ser más educado. [end]')\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "print(random.choice(text_pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4wOdzyimYpv"
      },
      "source": [
        "아래 코드는 텍스트를 무작위 섞은 다음\n",
        "70 대 15 대 15의 비율로 훈련 텍스트셋, 검증 텍스트셋, 테스트 텍스트셋으로 나눈다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK2mwr96T_5s"
      },
      "outputs": [],
      "source": [
        "random.shuffle(text_pairs)\n",
        "\n",
        "# 검증셋 크기: 전체 데이터셋의 15%\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "# 훈련셋 크기: 전체 데이터셋의 70%\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "\n",
        "# 훈련 텍스트셋\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "# 검증 텍스트셋\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "# 테스트 텍스트셋\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuqUCPshT_5s"
      },
      "source": [
        "**영어/스페인어 텍스트 벡터화**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx8cUdoSmYpv"
      },
      "source": [
        "자연어로 구성된 훈련 텍스트 데이터셋을 대상으로 어휘 인덱스를 생성한 후에 텍스트 벡터화를 진행한다.\n",
        "먼저 영어 어휘집을 생성한다.\n",
        "생성되는 어휘 벡터의 길이를 20으로 지정한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8CWdFJIT_5t"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "\n",
        "# 번역 대상 언어(예를 들어 영어) 텍스트 데이터셋 벡터화 층\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "# 영어 텍스트만 추출\n",
        "train_english_texts = [pair[0] for pair in train_pairs]\n",
        "# 영어 어휘집 생성\n",
        "source_vectorization.adapt(train_english_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQUdtTPUmYpv"
      },
      "source": [
        "스페인어 텍스트 벡터화는 영어와는 다른 표준화 방식을 사용한다.\n",
        "\n",
        "- 영어에는 없는 `'¿'` 기호도 표준화 과정에서 삭제\n",
        "- 반면에 `'['`와 `']'`는 표준화 과정에서 제거되지 않도록 지정\n",
        "\n",
        "또한 생성되는 어휘 벡터의 길이를 21로 지정한다.\n",
        "그러면 0번 인덱스부터 19번 인덱스까지는 입력값으로,\n",
        "1번 인덱스부터 20번 인덱스까지는 타깃으로 지정할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOwHngOWmYpv"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "# 마침표 기호 목록에 \"¿\" 추가. 즉 표준화과정에서 삭제 대상으로 지정.\n",
        "strip_chars = string.punctuation + \"¿\"\n",
        "# 마침표 기호 목록으로부터 \"[\" 와 \"]\" 제거. 즉, 표준화 대상에서 삭제하지 않도록 함.\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "# 새로운 표준화 함수 선언\n",
        "# 소문자로 변환한 후에 strip_chars 에 포함된 모든 기호 삭제\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "# 번역 언어 (예를 들어 스페인어) 텍스트 데이터셋 벡터화 층\n",
        "# 벡터의 길이를 20이 아닌 21로 지정. 입력값과 타깃을 구분하기 위해 필요함.\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "\n",
        "# 스페인어 텍스트만 추출\n",
        "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
        "# 스페인어 어휘집 생성\n",
        "target_vectorization.adapt(train_spanish_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7HeM8qPT_5t"
      },
      "source": [
        "훈련 텍스트셋, 검증 텍스트셋, 테스트 텍스트셋을 모두 어휘 인덱스를 이용하여 벡터화 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJHRYlxamYpw"
      },
      "source": [
        "아래 코드는 생성된 영어와 스페인어 어휘 인덱스를 이용하여 각각의 텍스트 데이터셋을\n",
        "벡터화 한 다음에 아래 모양의 튜플로 구성된 훈련셋, 검증셋, 테스트셋을 생성한다.\n",
        "\n",
        "- 튜플의 첫째 항목: 영어 입력 배치와 스페인어 입력 배치로 구성된 사전. 모델의 입력값으로 사용.\n",
        "- 튜플의 둘째 항목: 타깃 배치. 모델 훈련의 타깃으로 사용.\n",
        "\n",
        "```\n",
        "({\"english\": 영어 입력 배치, \"spanish\": 스페인어 입력 배치}, 타깃 배치)\n",
        "```\n",
        "\n",
        "- `format_dataset()` 함수\n",
        "    - 인자: 영어 텍스트 배치와 스페인어 텍스트 배치\n",
        "    - 반환값: 앞서 언급한 모양의 사전\n",
        "    \n",
        "- `make_dataset()` 함수\n",
        "    - 인자: `(영어 텍스트, 스페인어 텍스트)` 모양의 튜플로 구성된 자연어 텍스트 데이터셋\\\n",
        "    - 반환값: 지정된 배치 크기로 묶은 배치들에 대해 `format_dataset()` 함수를 적용하여\n",
        "        생성된 `Dataset` 자료형의 데이터셋. 배치 단위로 묶여 있음.\n",
        "        - `dataset.shuffle(2048).prefetch(16).cache()`: 대용량 데이터셋을 배치 단위로\n",
        "            빠르게 불러오기 위해 사용함.        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEgEfPpqT_5t"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "def format_dataset(eng, spa):\n",
        "    eng = source_vectorization(eng)\n",
        "    spa = target_vectorization(spa)\n",
        "    return ({\"english\": eng, \"spanish\": spa[:, :-1]}, spa[:, 1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    dataset = dataset.map(format_dataset)\n",
        "\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "# 훈련셋\n",
        "train_ds = make_dataset(train_pairs)\n",
        "# 검증셋\n",
        "val_ds = make_dataset(val_pairs)\n",
        "# 테스트셋\n",
        "test_ds = make_dataset(test_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndbPzWlSmYpw"
      },
      "source": [
        "예를 들어 훈련셋의 첫째 배치의 모양을 확인하면 다음과 같다.\n",
        "\n",
        "- 영어 입력 배치: 길이가 20인 64개의 벡터로 구성. 즉, 20 개의 단어로 구성된 영어 텍스트 64개로 구성됨.\n",
        "- 스페인어 입력 배치: 길이가 20인 64개의 벡터로 구성. 즉, 20 개의 단어로 구성된 스페인어 텍스트 64개로 구성됨.\n",
        "- 타깃 배치: 길이가 20인 64개의 벡터로 구성. 즉, 20 개의 단어로 구성된 스페인어 텍스트 64개로 구성됨."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvL9A1MQT_5t",
        "outputId": "1db6f2f6-6ba9-406d-80f6-adc0ae681426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs['english'].shape: (64, 20)\n",
            "inputs['spanish'].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
        "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8W4qfQnmYpw"
      },
      "source": [
        "아래 코드는 첫째 샘플의 영어 벡터, 스페인어 벡터, 타깃을 보여준다.\n",
        "스페인어 입력 벡터 샘플의 0번 인덱스에 위치한 정수 2가 `'[start]'`에 해당하는 값이다.\n",
        "스페인어 타깃 벡터 샘플은 그 값을 제외한 벡터로 시작함을 확인할 수 있다.\n",
        "또한 정수 3은 `'[end]'`에 해당하는 값이며, 문장의 끝을 가리키기에\n",
        "스페인어 타깃 벡터 샘플에 새로운 단어에 해당하는 인덱스를 추가하지 않고 대신 0 패딩이 하나 더 추가되었다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1db6f2f6-6ba9-406d-80f6-adc0ae681426",
        "id": "1c9iIt3omYpw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "영어 입력 벡터 샘플: [  3 351   4 738   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0]\n",
            "스페인어 입력 벡터 샘플: [   2 2208    4 5167    3    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n",
            "스페인어 타깃 샘플: [2208    4 5167    3    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f\"영어 입력 벡터 샘플: {inputs['english'][0]}\")\n",
        "    print(f\"스페인어 입력 벡터 샘플: {inputs['spanish'][0]}\")\n",
        "    print(f\"스페인어 타깃 샘플: {targets[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JE4Oo1FT_5x"
      },
      "source": [
        "### 트랜스포머 디코더"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nDTWDwkmYpw"
      },
      "source": [
        "트랜스포머 디코더를 하나의 층으로 구현하면 다음과 같다.\n",
        "생성자의 인자는 다음과 같다.\n",
        "\n",
        "- `embed_dim`: 예를 들어 `embed_dim=256`은 단어 임베딩 `(600, 256)` 모양의 샘플 생성\n",
        "- `dense_dim`: 밀집층에서 사용되는 유닛<font size='2'>unit</font> 개수\n",
        "- `num_heads`: 헤드<font size='2'>head</font> 개수\n",
        "\n",
        "`get_causal_attention_mask()` 메서드는 스페인어 입력 텍스트에 대한 마스크를 지정할 때 활용되지만\n",
        "여기서는 마스크를 사용하지 않는다.\n",
        "\n",
        "순전파를 담당하는 `call()` 메서드는 두 개의 어텐션 층을 사용한다.\n",
        "입력값으로는 스페인어 텍스트 배치 데이터셋과\n",
        "트랜스포머 디코더의 출력값으로 셀프 어텐션이 적용되어 변환된 영어 텍스트 배치 데이터셋이 사용된다.\n",
        "\n",
        "- `attention_1`: 스페인어 텍스트 입력값에 대해 셀프 어텐션 적용\n",
        "- `attention_2`: `attention_1` 의 출력값을 query로, 트랜스포머 인코더의 출력값을 key와 value로 사용해서 어텐션 적용.\n",
        "\n",
        "최종적으로 두 개의 밀집층을 통과시킨다.\n",
        "또한 하나의 블록을 통과시킬 때마다 잔차연결과 층정규화를 진행한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I9kRgqdT_5x"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        # 마스크 활용\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        # 셀프 어텐션 적용: 번역 언어(예를 들어 스페인어) 입력값 대상\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        # 셀프 어텐션이 적용된 (예를 들어 스페인어) 입력 텍스트를 query로\n",
        "        # 셀프 어텐션이 적용된 번역 대상 (예를 들어 영어) 입력 텍스트를 key와 value로\n",
        "        # 지정하여 어텐션 적용\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yw8lS_QT_5y"
      },
      "source": [
        "### 기계 번역 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5EQ_uhfmYpw"
      },
      "source": [
        "모델의 입력값은 앞서 설명한 대로 예를 들어 일정 길이로 단어 벡터화된 영어 텍스트 데이터셋과\n",
        "스페인어 텍스트 데이터셋의 튜플이다.\n",
        "스페인어 텍스트는 모두 `[start]` 로 시작하도록 전처리되어 있다.\n",
        "\n",
        "모델의 출력값은 예를 들어 출력 스페인어 텍스트로 지정될 단어들에 대한 위치별 확률값을 계산한다.\n",
        "아래 코드에서는 스페인어 텍스트에 포함될 20 개 단어들의 후보를 위치별로 확률값으로 계산한다.\n",
        "예를 들어 출력 텍스트의 i-번 인덱스에 위치할 단어의 확률값을 계산하기 위해\n",
        "어휘집에 포함된 15,000 개 단어를 대상으로 각각의 단어가 해당 위치에 자리할 확률을\n",
        "소프트맥스 함수를 이용하여 계산한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5B1RqwgT_5y"
      },
      "outputs": [],
      "source": [
        "sequence_length = 20 # 텍스트의 단어수\n",
        "vocab_size = 15000 # 어휘집 크기\n",
        "embed_dim = 256    # 단어 임베딩 크기\n",
        "dense_dim = 2048   # 밀집층 유닛수\n",
        "num_heads = 8      # 어텐션 헤드수\n",
        "\n",
        "# 트랜스포머 인코더 활용\n",
        "\n",
        "# 첫째 입력값: 예를 들어 영어 텍스트셋\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "# 트랜스포머 디코더 활용\n",
        "\n",
        "# 둘째 입력값: 예를 들어 스페인어 텍스트셋\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I53wCz6AT_5y"
      },
      "source": [
        "**모델 훈련과 활용**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsqth31gmYpw"
      },
      "source": [
        "모델의 최종 출력값이 소프트맥스를 사용하여\n",
        "`(20, 15000)` 모양을 갖는 반면에\n",
        "타깃셋은 20 개의 어휘 인덱스로 구성된 벡터로 구성되기에\n",
        "`categorical_crossentropy` 가 아닌 `sparse_categorical_crossentropy`를\n",
        "손실함수로 지정한다.\n",
        "그러면 20개 단어 각각에 대해 가장 높은 확률을 갖는 (어휘) 인덱스에 해당하는 단어가\n",
        "15,000 개 중에 선택되어 타깃 단어와 비교된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdbYo16QT_5y",
        "outputId": "494e1652-1a0f-440d-ec67-d77a613ed071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1547/1547 [==============================] - 10640s 67ms/step - loss: 3.6921 - accuracy: 0.4524 - val_loss: 2.7772 - val_accuracy: 0.5561\n",
            "Epoch 2/30\n",
            "1547/1547 [==============================] - 80s 51ms/step - loss: 2.7889 - accuracy: 0.5603 - val_loss: 2.4589 - val_accuracy: 0.6021\n",
            "Epoch 3/30\n",
            "1547/1547 [==============================] - 78s 51ms/step - loss: 2.5259 - accuracy: 0.6007 - val_loss: 2.3711 - val_accuracy: 0.6203\n",
            "Epoch 4/30\n",
            "1547/1547 [==============================] - 79s 51ms/step - loss: 2.3810 - accuracy: 0.6247 - val_loss: 2.3070 - val_accuracy: 0.6347\n",
            "Epoch 5/30\n",
            "1547/1547 [==============================] - 79s 51ms/step - loss: 2.2894 - accuracy: 0.6414 - val_loss: 2.3228 - val_accuracy: 0.6362\n",
            "Epoch 6/30\n",
            "1547/1547 [==============================] - 79s 51ms/step - loss: 2.2183 - accuracy: 0.6549 - val_loss: 2.2714 - val_accuracy: 0.6467\n",
            "Epoch 7/30\n",
            "1547/1547 [==============================] - 80s 51ms/step - loss: 2.1518 - accuracy: 0.6684 - val_loss: 2.2359 - val_accuracy: 0.6552\n",
            "Epoch 8/30\n",
            "1547/1547 [==============================] - 78s 51ms/step - loss: 2.0916 - accuracy: 0.6795 - val_loss: 2.2064 - val_accuracy: 0.6623\n",
            "Epoch 9/30\n",
            "1547/1547 [==============================] - 78s 51ms/step - loss: 2.0438 - accuracy: 0.6885 - val_loss: 2.2028 - val_accuracy: 0.6667\n",
            "Epoch 10/30\n",
            "1547/1547 [==============================] - 78s 50ms/step - loss: 2.0032 - accuracy: 0.6961 - val_loss: 2.1963 - val_accuracy: 0.6674\n",
            "Epoch 11/30\n",
            "1547/1547 [==============================] - 78s 50ms/step - loss: 1.9702 - accuracy: 0.7011 - val_loss: 2.2067 - val_accuracy: 0.6656\n",
            "Epoch 12/30\n",
            "1547/1547 [==============================] - 79s 51ms/step - loss: 1.9423 - accuracy: 0.7066 - val_loss: 2.2402 - val_accuracy: 0.6687\n",
            "Epoch 13/30\n",
            "1547/1547 [==============================] - 79s 51ms/step - loss: 1.9152 - accuracy: 0.7117 - val_loss: 2.2148 - val_accuracy: 0.6724\n",
            "Epoch 14/30\n",
            "1547/1547 [==============================] - 79s 51ms/step - loss: 1.8921 - accuracy: 0.7155 - val_loss: 2.2471 - val_accuracy: 0.6718\n",
            "Epoch 15/30\n",
            "1547/1547 [==============================] - 78s 51ms/step - loss: 1.8724 - accuracy: 0.7191 - val_loss: 2.2565 - val_accuracy: 0.6693\n",
            "Epoch 16/30\n",
            "1547/1547 [==============================] - 78s 50ms/step - loss: 1.8497 - accuracy: 0.7226 - val_loss: 2.2485 - val_accuracy: 0.6731\n",
            "Epoch 17/30\n",
            "1547/1547 [==============================] - 78s 50ms/step - loss: 1.8313 - accuracy: 0.7265 - val_loss: 2.2680 - val_accuracy: 0.6706\n",
            "Epoch 18/30\n",
            "1547/1547 [==============================] - 78s 50ms/step - loss: 1.8153 - accuracy: 0.7291 - val_loss: 2.2644 - val_accuracy: 0.6748\n",
            "Epoch 19/30\n",
            "1547/1547 [==============================] - 78s 51ms/step - loss: 1.7971 - accuracy: 0.7326 - val_loss: 2.2789 - val_accuracy: 0.6729\n",
            "Epoch 20/30\n",
            "1547/1547 [==============================] - 79s 51ms/step - loss: 1.7805 - accuracy: 0.7355 - val_loss: 2.2601 - val_accuracy: 0.6753\n",
            "Epoch 21/30\n",
            "1547/1547 [==============================] - 78s 51ms/step - loss: 1.7611 - accuracy: 0.7384 - val_loss: 2.2820 - val_accuracy: 0.6745\n",
            "Epoch 22/30\n",
            "1547/1547 [==============================] - 78s 50ms/step - loss: 1.7490 - accuracy: 0.7407 - val_loss: 2.2995 - val_accuracy: 0.6746\n",
            "Epoch 23/30\n",
            "1547/1547 [==============================] - 79s 51ms/step - loss: 1.7344 - accuracy: 0.7431 - val_loss: 2.2958 - val_accuracy: 0.6754\n",
            "Epoch 24/30\n",
            "1547/1547 [==============================] - 79s 51ms/step - loss: 1.7204 - accuracy: 0.7455 - val_loss: 2.2823 - val_accuracy: 0.6783\n",
            "Epoch 25/30\n",
            "1547/1547 [==============================] - 79s 51ms/step - loss: 1.7076 - accuracy: 0.7476 - val_loss: 2.3179 - val_accuracy: 0.6767\n",
            "Epoch 26/30\n",
            "1547/1547 [==============================] - 79s 51ms/step - loss: 1.6958 - accuracy: 0.7494 - val_loss: 2.3209 - val_accuracy: 0.6768\n",
            "Epoch 27/30\n",
            "1547/1547 [==============================] - 78s 50ms/step - loss: 1.6817 - accuracy: 0.7525 - val_loss: 2.3500 - val_accuracy: 0.6797\n",
            "Epoch 28/30\n",
            "1547/1547 [==============================] - 78s 51ms/step - loss: 1.6682 - accuracy: 0.7547 - val_loss: 2.3766 - val_accuracy: 0.6750\n",
            "Epoch 29/30\n",
            "1547/1547 [==============================] - 79s 51ms/step - loss: 1.6578 - accuracy: 0.7564 - val_loss: 2.3624 - val_accuracy: 0.6767\n",
            "Epoch 30/30\n",
            "1547/1547 [==============================] - 79s 51ms/step - loss: 1.6461 - accuracy: 0.7585 - val_loss: 2.3792 - val_accuracy: 0.6733\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fca247bce50>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "transformer.fit(train_ds, epochs=30, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_2veTqxT_5y"
      },
      "source": [
        "아래 `decode_sequence()`는 함수는 영어 텍스트가 하나 입력되면\n",
        "앞서 훈련된 트랜스포머 모델을 이용하여 지정된 길이인 20 개의 단어로\n",
        "구성된 스페인어 텍스트를 생성한다.\n",
        "\n",
        "함수 본문에 포함된 `for` 반복문은\n",
        "**트랜스포머 모델 활용** 부분에서 설명한 방식 그대로\n",
        "`[start]`로만 구성된 텍스트로 시작해서\n",
        "계속해서 텍스트에 추가할 단어를 하나씩 선택해서 이어가는 과정을\n",
        "`[end]` 키워드가 나올 때까지 반복한다.\n",
        "단, 반복횟수는 20으로 제한한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtl4ic-tT_5y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 어휘집 확인\n",
        "spa_vocab = target_vectorization.get_vocabulary()\n",
        "# (단어 인덱스, 단어)로 구성된 사전 지정\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "# 텍스트에 포함되는 단어수\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    # 기계 번역 시작\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        # 트랜스포머 모델 적용\n",
        "        tokenized_target_sentence = target_vectorization(\n",
        "            [decoded_sentence])[:, :-1]\n",
        "        predictions = transformer(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        # i-번째 단어로 사용될 어휘 인덱스 확인\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        # i-번째 단어 확인\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        # 스페인어 입력 텍스트에 i-번째 단어로 추가\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        # 기계 번역 종료 조건 확인\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAaLwWR2mYpx"
      },
      "source": [
        "아래 코드는 `decode_sequence()` 함수를 이용하여\n",
        "무작위로 5개의 영어 텍스트를 선택하여 기계 번역한 결과이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFJXavRueOZC",
        "scrolled": false,
        "outputId": "8049ba3f-464e-4a7f-b352-4bc56aa3994c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-\n",
            "You should not despise a man because he is poor.\n",
            "[start] no debes hacer pobre [UNK] a un pobre [end]\n",
            "-\n",
            "I'm calling you.\n",
            "[start] te estoy todavía [end]\n",
            "-\n",
            "The influence of TV on society is great.\n",
            "[start] la montaña de la gente de la [UNK] es muy importante [end]\n",
            "-\n",
            "Did Tom listen to you?\n",
            "[start] tom te escuchando [end]\n",
            "-\n",
            "My plan was eventually adopted.\n",
            "[start] mi plan fue al final [end]\n"
          ]
        }
      ],
      "source": [
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "\n",
        "for _ in range(5):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(decode_sequence(input_sentence))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "6c86b3592b6800d985c04531f2c445f0fa6967131b8dd6395a925f7622e55602"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}